{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6518a2b2cf24b259",
   "metadata": {},
   "source": [
    "# This Notebook Runs Baselines (BPOSD, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T15:20:13.964464Z",
     "start_time": "2025-11-18T15:20:13.959741Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from functools import partial\n",
    "from io import StringIO\n",
    "from operator import itemgetter\n",
    "\n",
    "from surface_sim.setups.setup import SetupDict\n",
    "\n",
    "from mccd.random_clifford_circuit import *\n",
    "from surface_sim.setups import CircuitNoiseSetup\n",
    "from surface_sim.models import CircuitNoiseModel, BiasedCircuitNoiseModel\n",
    "from surface_sim import Detectors, Setup\n",
    "from surface_sim.experiments import schedule_from_circuit, experiment_from_schedule\n",
    "import time\n",
    "import stim\n",
    "\n",
    "from pathlib import Path\n",
    "import stim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import itertools\n",
    "import shelve\n",
    "from surface_sim.layouts import rot_surface_codes\n",
    "\n",
    "from pymatching import Matching as MWPM\n",
    "from mle_decoder import MLEDecoder as MLE\n",
    "from stimbposd import BPOSD\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['GRB_LICENSE_FILE'] = '/Users/fengcong/.gurobi/gurobi.lic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e5eadad6e4442",
   "metadata": {},
   "source": [
    "## Baseline Decoders\n",
    "\n",
    "- MWPM. We use the open-source library PyMatching with the noise model used for data generation as detailed in the ‘Experimentally motivated noise model’ subsection.\n",
    "\n",
    "- BP-OSD. We use the open-source library stimbposd. We use the exact noise model used for data generation and set the maximal belief propagation iterations to 20.\n",
    "\n",
    "- MLE. We use the algorithm developed and implemented as in ref. 14.\n",
    "\n",
    "### Notes\n",
    "\n",
    "All baselines have PyPI packages.\n",
    "\n",
    "```\n",
    "pymatching\n",
    "mle-decoder\n",
    "stimbposd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6d637b34a96b137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T23:51:36.884043Z",
     "start_time": "2025-11-18T23:51:36.879934Z"
    }
   },
   "outputs": [],
   "source": [
    "DECODER_BASELINES = {\n",
    "    'BPOSD': partial(BPOSD, max_bp_iters=20),\n",
    "    'MLE': MLE, # TODO: model too large. acacdemic license.\n",
    "    'MWPM': MWPM,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5575f8456d525",
   "metadata": {},
   "source": [
    "## Basic Gates & Surface Code\n",
    "\n",
    "MCCD uses I, X, Y, Z, H (single qubit gates) and CX (two qubit gates).\n",
    "\n",
    "MCCD uses Rotated Surface Code.\n",
    "\n",
    "surface-sim supports I, X, Z for rotated gates and I, H, X, Z for unrotated gates.\n",
    "\n",
    "### Notes\n",
    "\n",
    "We use the gates which `surface-sim` supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf692d72b04c3c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T15:20:14.009487Z",
     "start_time": "2025-11-18T15:20:14.002943Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_random_circuit(c: RandomCliffordCircuit):\n",
    "    return list(c)\n",
    "\n",
    "def dict_product(input_dict):\n",
    "    keys = input_dict.keys()\n",
    "    value_lists = input_dict.values()\n",
    "\n",
    "    # 使用itertools.product生成所有值的组合\n",
    "    value_combinations = itertools.product(*value_lists)\n",
    "\n",
    "    # 将每个值的组合与键配对，生成字典列表\n",
    "    for combo in value_combinations:\n",
    "        yield dict(zip(keys, combo))\n",
    "\n",
    "def run_decoder(name: str, circuit: stim.Circuit, shots: int):\n",
    "    \"\"\"Runs decoder on the given circuit\n",
    "\n",
    "    Args:\n",
    "        name: decoder name\n",
    "        circuit: circuit to run\n",
    "        shots: number of shots\n",
    "\n",
    "    Returns:\n",
    "        A dict containing the decoder metrics.\n",
    "    \"\"\"\n",
    "    method = DECODER_BASELINES[name](circuit.detector_error_model())\n",
    "    sampler = circuit.compile_detector_sampler()\n",
    "    syndrome, labels = sampler.sample(shots=shots, separate_observables=True)\n",
    "    begin = time.time_ns()\n",
    "    predictions = method.decode_batch(syndrome)\n",
    "    end = time.time_ns()\n",
    "    logical_accuracy = accuracy_score(labels, predictions)\n",
    "    walltime_seconds = (end - begin) / 1e9\n",
    "    return dict(\n",
    "        decoder=name,\n",
    "        logical_accuracy=logical_accuracy,\n",
    "        walltime_seconds=walltime_seconds,\n",
    "    )\n",
    "\n",
    "def run_decoder_tasks(root_dir, bench_circuits, bench_decoders, df_name):\n",
    "    \"\"\"Run all the baseline decoders on the benchmark circuit.\n",
    "\n",
    "    Args:\n",
    "        bench_circuits: Benchmark circuits.\n",
    "        df_name: Name of the dataframe file.\n",
    "\n",
    "    Returns:\n",
    "        The result dataframe.\n",
    "    \"\"\"\n",
    "    root_dir = Path(root_dir) / df_name\n",
    "    root_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def run_decoder_plus(config, cir_str, i, **kwargs):\n",
    "        res = config.copy()\n",
    "        res.update(kwargs)\n",
    "        save_dir = root_dir / f'res{i}.json'\n",
    "        save_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if save_dir.is_file():\n",
    "            return\n",
    "\n",
    "        kwargs['circuit'] = stim.Circuit.from_file(StringIO(cir_str))\n",
    "        try:\n",
    "            res.update(run_decoder(**kwargs))\n",
    "            save_dir.write_text(json.dumps(res))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def tasks():\n",
    "        i = 0\n",
    "        for phy_cir, config in bench_circuits:\n",
    "            for decoder in bench_decoders:\n",
    "                i += 1\n",
    "                yield delayed(run_decoder_plus)(config, phy_cir, i-1,\n",
    "                                                name=decoder, shots=num_shots)\n",
    "\n",
    "    Parallel(n_jobs=-1, verbose=1)(tasks())\n",
    "\n",
    "    bench_result = list(root_dir.glob('res*.json'))\n",
    "\n",
    "    df = pd.DataFrame.from_records(bench_result)\n",
    "    df = pd.melt(df, id_vars=['decoder', 'distance', 'depth', 'circuit_type_index'],\n",
    "             value_vars=['walltime_seconds', 'logical_accuracy'],\n",
    "             var_name='metric',\n",
    "             value_name='value')\n",
    "\n",
    "    filename = root_dir / '..' / f'{df_name}.csv'\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print('done')\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_circuits(root_dir: Path):\n",
    "    circuits = []\n",
    "    for config_path in sorted(root_dir.glob('*_config.json')):\n",
    "        config = json.loads(config_path.read_text())\n",
    "\n",
    "        for cir_path in sorted(root_dir.glob(config_path.stem.replace('_config', '_phy_trial*.stim'))):\n",
    "            phy_cir = stim.Circuit.from_file(cir_path)\n",
    "            circuits.append((str(phy_cir), config))\n",
    "\n",
    "    return circuits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8625e62825c7b89",
   "metadata": {},
   "source": [
    "## Circuit Depths\n",
    "\n",
    "From released source_data.zip, Type I circuits have depths:\n",
    "\n",
    "array([ 2,  4,  6,  8, 10, 12, 14, 16, 18])\n",
    "\n",
    "Type II circuits have depths:\n",
    "\n",
    "array([ 4,  8, 12, 16, 20, 24, 28, 32, 36])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29457b33bea890",
   "metadata": {},
   "source": [
    "### Shots & Repeat\n",
    "We evaluate each decoder over 20 independent runs. In each run, we randomly sample 1,000 syndrome trajectories from Type I/II circuits and average them to obtain a run-level performance estimate. We report the mean across the 20 runs, with error bars showing s.e.m.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f4c93",
   "metadata": {},
   "source": [
    "Load circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab470233",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model = 'average_depolarizing_noise'\n",
    "root_dir = Path('./data/bench') / noise_model\n",
    "num_shots = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f78fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4_circuits = load_circuits(root_dir / 'fig4/circuits')\n",
    "fig5_circuits = load_circuits(root_dir / 'fig5/circuits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b456f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fig4_circuits), len(fig5_circuits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271e3969f88315c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T00:01:20.658111Z",
     "start_time": "2025-11-19T00:01:18.936271Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed: 52.5min\n",
      "/Users/fengcong/miniconda3/envs/py312/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2739212\n",
      "Academic license - for non-commercial use only - expires 2026-11-15\n",
      "\n",
      "Interrupt request received\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df4 = \u001b[43mrun_decoder_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresult\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfig4_circuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDECODER_BASELINES\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfig4-baselines\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mrun_decoder_tasks\u001b[39m\u001b[34m(root_dir, bench_circuits, bench_decoders, df_name)\u001b[39m\n\u001b[32m     71\u001b[39m             i += \u001b[32m1\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m delayed(run_decoder_plus)(config, phy_cir, i-\u001b[32m1\u001b[39m,\n\u001b[32m     73\u001b[39m                                             name=decoder, shots=num_shots)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m bench_result = \u001b[38;5;28mlist\u001b[39m(root_dir.glob(\u001b[33m'\u001b[39m\u001b[33mres*.json\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     79\u001b[39m df = pd.DataFrame.from_records(bench_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py312/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py312/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py312/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df4 = run_decoder_tasks(root_dir / 'fig4/result',\n",
    "    fig4_circuits, DECODER_BASELINES.keys(), 'fig4-baselines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e7c7d8ab84a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T23:45:56.115168Z",
     "start_time": "2025-11-18T15:57:34.927952Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = run_decoder_tasks(root_dir / 'fig5/result',\n",
    "    fig5_circuits, DECODER_BASELINES.keys(), 'fig5-baselines')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
